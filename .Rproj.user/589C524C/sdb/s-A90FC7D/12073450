{
    "contents" : "get.sample.nobs  <- function(svy.imp.design, group=NULL) {\n    if(is.null(group)) {\n\tnobs.imp <- lapply(svy.imp.design[[1]], function(des) {nrow(des$variables)})\n\treturn(median(unlist(nobs.imp)))\n    }\n    # Multiple group analysis\n    # TODO\n}\n\nlavaan.survey <- function(lavaan.fit, survey.design, \n\t     estimator=c(\"MLM\", \"MLMV\", \"MLMVS\", \"WLS\", \"DWLS\", \"ML\"),\n\t     estimator.gamma=c(\"default\",\"Yuan-Bentler\")) {\n  estimator <- match.arg(estimator)\n  estimator.gamma <- match.arg(estimator.gamma)\n  ov.names <- lavaan.fit@Data@ov.names[[1]]\n  Dplus <- ginv(lavaan::duplicationMatrix(length(ov.names)))\n  ov.formula <- as.formula(paste(\"~\",paste(ov.names, collapse=\"+\")))\n  \n  Gamma <- vector(\"list\", lavaan.fit@Data@ngroups)\n  sample.cov <- vector(\"list\", lavaan.fit@Data@ngroups)\n  sample.mean <- vector(\"list\", lavaan.fit@Data@ngroups)\n  \n  for(g in seq(lavaan.fit@Data@ngroups)) {\n    if(lavaan.fit@Data@ngroups > 1) {\n      survey.design.g <- subset(survey.design, eval(parse(text=sprintf(\"%s == '%s'\", \n                              lavaan.fit@call$group, lavaan.fit@Data@group.label[[g]]))))\n    } else { survey.design.g <- survey.design  }\n    \n\n    get.stats.design <- function(survey.design.g, sample.nobs) {\n\tsample.cov.g <- as.matrix(svyvar(ov.formula, design=survey.design.g, na.rm=TRUE))  \n\tGamma.cov.g <- attr(sample.cov.g, \"var\")\n\tGamma.cov.g <- Dplus %*% Gamma.cov.g %*% t(Dplus)\n      \n\tsample.mean.g <- svymean(ov.formula, design=survey.design.g, na.rm=TRUE)  \n\tGamma.mean.g <- attr(sample.mean.g, \"var\")\n\tGamma.g <- as.matrix(Matrix::bdiag(Gamma.mean.g, Gamma.cov.g)) # TODO add offdiag\n\t\n\tGamma.g <- Gamma.g * sample.nobs[g]\n\t\n\tif(estimator.gamma == \"Yuan-Bentler\") {\n\t    r <- get.residuals(lavaan.fit)\n\t    Gamma.g <- Gamma.g + (sample.nobs[g]/(sample.nobs[g] - 1)) * (r %*% t(r))\n\t}\n\t# This has to be at the end or lazy evaluation mayhem will ensue:\n\tattr(sample.cov.g, \"var\") <- NULL\n\ttmp  <- as.vector(sample.mean.g)\n\tnames(tmp) <- names(sample.mean.g)\n\tsample.mean.g <- tmp\t\n\n\tlist(Gamma.g=Gamma.g, sample.cov.g=sample.cov.g, sample.mean.g=sample.mean.g)\n    }\n    if(!any(class(survey.design.g) == \"svyimputationList\")) {\n        sample.nobs <- unlist(lavaan.fit@Data@nobs)\n\tstats <- get.stats.design(survey.design.g, sample.nobs)\n    } else {\n\t# Not only can nobs differ from lavaan.fit, but also per imputation\n\tsample.nobs <- get.sample.nobs(survey.design.g, lavaan.fit@call$group)\n\tstats.list <- lapply(survey.design.g[[1]], get.stats.design, sample.nobs=sample.nobs)\n\tm  <- length(stats.list)\n\tsample.cov.list <- lapply(stats.list, `[[`, 'sample.cov.g')\n\tsample.cov.g <- Reduce(`+`, sample.cov.list) / m\n\tcov.df <- Reduce(`rbind`, lapply(sample.cov.list, vech))\n\tsample.mean.list <- lapply(stats.list, `[[`, 'sample.mean.g')\n\tsample.mean.g <- Reduce(`+`, sample.mean.list) / m\n\tmean.df <- Reduce(`rbind`, sample.mean.list)\n\n\tGamma.within  <- Reduce(`+`, lapply(stats.list, `[[`, 'Gamma.g')) / m\n\tGamma.between <- cov(cbind(mean.df, cov.df))\n\tGamma.g <- Gamma.within + ((m + 1)/m) * Gamma.between\n\t\n\tstats <- list(Gamma.g=Gamma.g, sample.cov.g=sample.cov.g, sample.mean.g=sample.mean.g)\n    }\n\n\n    Gamma[[g]] <- stats$Gamma.g\n    sample.cov[[g]] <- stats$sample.cov.g\n    sample.mean[[g]] <- stats$sample.mean.g\n  }\n  \n  new.call <- lavaan.fit@call\n  new.call$data <- NULL                # Remove any data argument\n  new.call$sample.cov <- sample.cov    # Set survey covariances\n  new.call$sample.mean <- sample.mean  # Set survey means\n  new.call$sample.nobs <- sample.nobs  \n  new.call$estimator <- estimator  # Always use Satorra-Bentler or WLS estimator\n  if(substr(estimator, 1, 2) == \"ML\") { # ML, robust options\n     # Set asymptotic covariance matrix of sample means and covariances\n     new.call$NACOV <- Gamma      \n  }\n  if(estimator %in% c(\"WLS\", \"DWLS\")) {\n     # Weighted Least Squares, adjust the weight matrix: MP inverse of Gamma\n     new.call$WLS.V <- lapply(Gamma, ginv)\n  }\n  new.fit <- eval(new.call) # Run lavaan with the new arguments\n  \n  if(estimator %in% c(\"WLS\", \"DWLS\")) return(new.fit) # We are done for WLS\n\n  # Code below should really be implemented in lavaan...\n\n  # For ML with robust se's, check that a possibly singular Gamma has not\n  # created dependencies in the parameter estimates\n  evs.too.small <- sapply(Gamma, function(Gamma.g) \n\t\t\t  any(eigen(Gamma.g, only.values=TRUE)$values < .Machine$double.eps*10))\n  if(any(evs.too.small)) {\n     V.est <- vcov(new.fit)\n     if(any(eigen(V.est, only.values=TRUE)$values < (.Machine$double.eps*10))) {\n\t long.string  <- sprintf(\"Some of the standard errors may not be trustworthy.\n\t\t\t Some of the observed covariances or means are\n\t\t\t collinear, and this has generated collinearity in your\n\t\t\t parameter estimates.  This may be a sample size issue,\n\t\t\t missing data problem, or due to having too few\n\t\t\t clusters relative to the number of parameters. Problem\n\t\t\t encountered in group(s) %s\",\n\t\t\t paste(which(evs.too.small), collapse=\", \"))\n         warning(strwrap(long.string, width=9999, simplify=TRUE))#gotta love it\n     }\n  }\n  \n  new.fit\n}\n\n\nget.residuals <- function(fit) {\n    r  <- residuals(fit)\n    c(r$mean, vech(r$cov))\n}\n",
    "created" : 1360149990252.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1902424211",
    "id" : "12073450",
    "lastKnownWriteTime" : 1354177642,
    "path" : "~/Dropbox/Development/lavaan.survey/lavaan.survey/R/lavaan.survey.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}